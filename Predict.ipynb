{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2024-04-01 23:37:53] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco_pose dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2024-04-01 23:37:53] INFO - checkpoint_utils.py - License Notification: YOLO-NAS-POSE pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS-POSE.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "[2024-04-01 23:37:54] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_pose_l\n",
            "[2024-04-01 23:37:54] INFO - checkpoint_utils.py - Successfully loaded model weights from .\\Models\\yolo_nas_pose_l_coco_pose.pth checkpoint.\n"
          ]
        }
      ],
      "source": [
        "from super_gradients.training import models\n",
        "from super_gradients.common.object_names import Models\n",
        "\n",
        "yolo_nas_pose = models.get(\"yolo_nas_pose_l\", pretrained_weights=\"coco_pose\", checkpoint_path=\".\\\\Models\\\\yolo_nas_pose_l_coco_pose.pth\").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7Hj6SPostkhs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "class ImageToArrayPreprocessor:\n",
        "    def __init__(self, dataFormat=None):\n",
        "        self.dataFormat = dataFormat\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        return img_to_array(image, data_format=self.dataFormat)\n",
        "\n",
        "class SimplePreprocessor:\n",
        "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.inter = inter\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "A7TVeh4rc-BB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from scipy.stats import mode\n",
        "\n",
        "class_names = ['barbell biceps curl',\n",
        "'bench press',\n",
        "'chest fly machine',\n",
        "'deadlift',\n",
        "'decline bench press',\n",
        "'hammer curl',\n",
        "'hip thrust',\n",
        "'incline bench press',\n",
        "'lat pulldown',\n",
        "'lateral raise',\n",
        "'leg extension',\n",
        "'leg raises',\n",
        "'normal',\n",
        "'plank',\n",
        "'pull Up',\n",
        "'push-up',\n",
        "'romanian deadlift',\n",
        "'russian twist',\n",
        "'shoulder press',\n",
        "'squat',\n",
        "'t bar row',\n",
        "'tricep Pushdown',\n",
        "'tricep dips']\n",
        "\n",
        "image_width, image_height = 64, 64\n",
        "model_path = './/Models//Resnet_skeleton.keras'\n",
        "sp = SimplePreprocessor(image_width, image_height)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "model_predict = load_model(model_path)\n",
        "def predict_image(frames, no_batch_size=32):\n",
        "  preprocessedFrames = []\n",
        "  for frame in frames:\n",
        "      frame = sp.preprocess(frame)  # Thay đổi kích thước\n",
        "      frame = iap.preprocess(frame)  # Chuyển đổi sang mảng\n",
        "      preprocessedFrames.append(frame)\n",
        "\n",
        "  frames = np.array(preprocessedFrames, dtype=\"float\") / 255.0  # Chuẩn hóa\n",
        "  predictions = model_predict.predict(frames, batch_size=no_batch_size)  # Dự đoán\n",
        "  # Lấy chỉ số lớp với xác suất cao nhất cho mỗi mẫu\n",
        "  class_indices = np.argmax(predictions, axis=1)\n",
        "  print(class_indices)\n",
        "  counts = np.bincount(class_indices)\n",
        "  if np.argmax(counts) == 12:\n",
        "        counts_temp = counts.copy()\n",
        "        counts_temp[12] = -1\n",
        "        most_common_class_idx = np.argmax(counts_temp)\n",
        "  else:\n",
        "      most_common_class_idx = np.argmax(counts)\n",
        "\n",
        "  print(class_names[most_common_class_idx])\n",
        "  return most_common_class_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from super_gradients.training.utils.visualization.detection import draw_bbox\n",
        "from super_gradients.training.utils.visualization.pose_estimation import PoseVisualization\n",
        "\n",
        "def process_single_image(image_prediction, largest_bbox_idx):\n",
        "    image = image_prediction.image\n",
        "    pose_data = image_prediction.prediction\n",
        "\n",
        "    # Lấy box của pose có chỉ số largest_bbox_idx\n",
        "    bbox = pose_data.bboxes_xyxy[largest_bbox_idx]\n",
        "    x1, y1, x2, y2 = bbox\n",
        "\n",
        "    # Tính toán tâm và kích thước mới của box\n",
        "    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "\n",
        "    # Mở rộng box ra 20%\n",
        "    new_width, new_height = width * 1.2, height * 1.2\n",
        "    new_x1, new_y1 = center_x - new_width / 2, center_y - new_height / 2\n",
        "    new_x2, new_y2 = center_x + new_width / 2, center_y + new_height / 2\n",
        "\n",
        "    # Điều chỉnh để không vượt qua ranh giới của ảnh\n",
        "    new_x1, new_y1 = max(new_x1, 0), max(new_y1, 0)\n",
        "    new_x2, new_y2 = min(new_x2, image.shape[1]), min(new_y2, image.shape[0])\n",
        "\n",
        "    # Crop ảnh\n",
        "    cropped_image = image[int(new_y1):int(new_y2), int(new_x1):int(new_x2)]\n",
        "\n",
        "    # Tạo một bản sao của ảnh để vẽ lên\n",
        "    blank_image = np.zeros_like(cropped_image)\n",
        "\n",
        "    # Lấy chỉ một pose tương ứng với hộp giới hạn lớn nhất\n",
        "    single_pose = np.expand_dims(pose_data.poses[largest_bbox_idx], axis=0)\n",
        "\n",
        "    # Cập nhật tọa độ của pose sau khi crop\n",
        "    single_pose[:, :, 0] -= new_x1\n",
        "    single_pose[:, :, 1] -= new_y1\n",
        "\n",
        "    # Vẽ khung xương cho pose đó\n",
        "    skeleton_image = PoseVisualization.draw_poses(\n",
        "        image=blank_image,\n",
        "        poses=single_pose,\n",
        "        boxes=None,  # Không hiển thị hộp giới hạn\n",
        "        scores=None,  # Bỏ qua điểm số cho ví dụ này\n",
        "        is_crowd=None,\n",
        "        edge_links=pose_data.edge_links,\n",
        "        edge_colors=pose_data.edge_colors,\n",
        "        keypoint_colors=pose_data.keypoint_colors,\n",
        "        joint_thickness=5,\n",
        "        keypoint_radius=20\n",
        "    )\n",
        "    return skeleton_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fcK39jX_peni"
      },
      "outputs": [],
      "source": [
        "def process_video(video_path, frame_interval=200):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "      print(\"Error: Could not open video.\")\n",
        "      exit()\n",
        "  frames = []\n",
        "  frame_count = 0\n",
        "  current_time = 0\n",
        "  while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break\n",
        "      current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "\n",
        "      if current_time >= frame_count * frame_interval:\n",
        "        results = yolo_nas_pose.to('cuda').predict(frame, conf=.25, fuse_model=False)\n",
        "        bboxes_xyxy = results.prediction.bboxes_xyxy\n",
        "        if len(bboxes_xyxy) > 0:\n",
        "          # Tính diện tích của các hộp giới hạn nếu có\n",
        "          areas = (bboxes_xyxy[:, 2] - bboxes_xyxy[:, 0]) * (bboxes_xyxy[:, 3] - bboxes_xyxy[:, 1])\n",
        "          index_of_largest_bbox = np.argmax(areas)\n",
        "          # Xử lý và hiển thị ảnh với khung xương của hộp giới hạn lớn nhất\n",
        "          skeleton_image = process_single_image(results, index_of_largest_bbox)\n",
        "          frames.append(skeleton_image)\n",
        "  cap.release()\n",
        "  predicted_class = predict_image(frames)\n",
        "  return predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HvhdKE6X2PQP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\\Data1\\bench press\\bench press_1.mp4\n",
            "11/11 [==============================] - 4s 287ms/step\n",
            "[18  1 10 10 10 10 14 22 10 14 14 14 10 18 18  1  6  6 14 14 14 14 14 14\n",
            " 14 14 18 14 12 14 14 14 10 12  1  1 12 10 10  8 14  8 10 10 10 10 10 10\n",
            " 10 10 10 10 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 10 10 10 14 10\n",
            " 14 12 17 10 10 12 12 14 18  1  8 14 10 10  1 10 10 10 10 10 18 18 18 18\n",
            " 18 18 18 18 18 18 10 10 10 15 10 10 10 10 10 14 12 10 10 18 18  8 14 14\n",
            "  8 14 14 14 14 14 14 14 14  8 14 18 14 18 18 18 18 10 12 10 10 10 10 10\n",
            " 10 10 10 10 10 10 18 10 10 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
            " 18 12 18 18 18 12 12 18 18 18 18 10 18 12 14 14 14 14 14 14 14 14 12  1\n",
            " 12 14 14 14 14 14 10 10 10 10 10 10 10 10 18 18 18 18  8 12 18 18 12 10\n",
            " 12 18 18 18 18 18 18 18 18 18 18 18 18 10  1  1 12 10 18 18 18 10 12 10\n",
            " 10 12 14 12 14 12 14 12 12 14 14 14 14 14 14 14 14 12 12 12 10 18 18 18\n",
            " 18 18 12 18 18 12 12 12 18 18 18 18 18 18 18 18 18 18 18 18 18 18 12  1\n",
            " 12 12 18 18 10 12 12 12 10 12 12 14 14 12 12 12 12 14 12 12 12 12 12 14\n",
            " 14 14 14 14 14 10 18 18 18 18 18 18 18 18 18 12 18 10 18 18 12 18 18 18]\n",
            "shoulder press\n",
            ".\\Data1\\bench press\\bench press_2.mp4\n",
            "6/8 [=====================>........] - ETA: 0s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 276ms/step\n",
            "[ 3 20 12  3 10 10  3  6  6  6 10 10 10 10  6  6  6  6  4  6  6  6 10  6\n",
            "  6  6  6  6  6  6  6  6  6 10  6 10 10 10 10 10  3 10 10 10 10 16  3  1\n",
            " 10 10 12 12 12 12 10 10 10  6  6 10  6  1  1  6  6  4  4  6  6  4  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  4  6  6  6  6  6  6  6  6 10 10\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  6  6  6  6  4\n",
            "  6  6  6  6  6  6  6  6  6 10 10 10 10 10 10 13 10 13 10 10 10 10 10 10\n",
            " 10 10 10 10 10 10 10  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 10\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  6 10\n",
            "  6 10  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 10 10 10 10 10 10 10\n",
            " 10 10 10 12 10 12 10 10 10 10 10 10 13 10 10 10  6  6  6  3 12 12]\n",
            "leg extension\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def process_folders(root_dir):\n",
        "    labels = []\n",
        "    video_names = []\n",
        "    for folder in os.listdir(root_dir):\n",
        "        video_dir = os.path.join(root_dir, folder)\n",
        "        if os.path.isdir(video_dir):\n",
        "            for video_file in os.listdir(video_dir):\n",
        "                video_names.append(video_file)\n",
        "                video_path = os.path.join(video_dir, video_file)\n",
        "                print(video_path)\n",
        "                if os.path.isfile(video_path):\n",
        "                    predicted_label = process_video(video_path)\n",
        "                    predicted_label = class_names[predicted_label]\n",
        "                    labels.append(predicted_label)\n",
        "    return labels, video_names\n",
        "\n",
        "# Example usage\n",
        "root = '.\\\\Dataset'\n",
        "labels, video_names = process_folders(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def write_arrays_to_csv(file_path, array1, array2):\n",
        "    # Open the CSV file for writing\n",
        "    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        \n",
        "        # Write the header row\n",
        "        writer.writerow(['video', 'Dự đoán'])\n",
        "        \n",
        "        # Write the data from the arrays to the file\n",
        "        for i in range(max(len(array1), len(array2))):\n",
        "            value1 = array1[i] if i < len(array1) else ''\n",
        "            value2 = array2[i] if i < len(array2) else ''\n",
        "            writer.writerow([value1, value2])\n",
        "# Call the function to create the CSV file and write the arrays to it\n",
        "write_arrays_to_csv('data.csv', video_names, labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
